{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://kean-chan.medium.com/real-time-facial-recognition-with-pytorch-facenet-ca3f6a510816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/Documents/Programming/ObjectDetection/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "from tqdm import tqdm\n",
    "from types import MethodType\n",
    "\n",
    "### helper function\n",
    "def encode(img):\n",
    "    res = resnet(torch.Tensor(img))\n",
    "    return res\n",
    "\n",
    "def detect_box(self, img, save_path=None):\n",
    "    # Detect faces\n",
    "    batch_boxes, batch_probs, batch_points = self.detect(img, landmarks=True)\n",
    "    # Select faces\n",
    "    if not self.keep_all:\n",
    "        batch_boxes, batch_probs, batch_points = self.select_boxes(\n",
    "            batch_boxes, batch_probs, batch_points, img, method=self.selection_method\n",
    "        )\n",
    "    # Extract faces\n",
    "    faces = self.extract(img, batch_boxes, save_path)\n",
    "    return batch_boxes, faces\n",
    "\n",
    "\n",
    "### load model\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "mtcnn = MTCNN(\n",
    "  image_size=224, keep_all=True, thresholds=[0.4, 0.5, 0.5], min_face_size=60\n",
    ")\n",
    "mtcnn.detect_box = MethodType(detect_box, mtcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photo_1.jpg:\n",
      "../data/images/photo_1.jpg\n",
      "ZowjqYGdvbg_1_1.jpg:\n",
      "../data/images/ZowjqYGdvbg_1_1.jpg\n",
      "IMG_20221130_171901_617_1.jpg:\n",
      "../data/images/IMG_20221130_171901_617_1.jpg\n",
      "IMG_20230201_000037_1.jpg:\n",
      "../data/images/IMG_20230201_000037_1.jpg\n",
      "IMG_20230131_235814_1.jpg:\n",
      "../data/images/IMG_20230131_235814_1.jpg\n",
      "7Dy2eue2_3I_1.jpg:\n",
      "../data/images/7Dy2eue2_3I_1.jpg\n",
      "MicrosoftTeams-image (2)_1.jpg:\n",
      "../data/images/MicrosoftTeams-image (2)_1.jpg\n",
      "0je5b4V4MQ0_1.jpg:\n",
      "../data/images/0je5b4V4MQ0_1.jpg\n",
      "mBpuNzIMJFY.jpg:\n",
      "../data/images/mBpuNzIMJFY.jpg\n",
      "IMG_20230201_000034_1.jpg:\n",
      "../data/images/IMG_20230201_000034_1.jpg\n",
      "IMG_20230131_235833_1.jpg:\n",
      "../data/images/IMG_20230131_235833_1.jpg\n",
      "photo3_medium_1.jpg:\n",
      "../data/images/photo3_medium_1.jpg\n",
      "w_7fa4706c_1_1.jpg:\n",
      "../data/images/w_7fa4706c_1_1.jpg\n",
      "AD87rlDaNs8_1.jpg:\n",
      "../data/images/AD87rlDaNs8_1.jpg\n",
      "photo2-1_1.jpg:\n",
      "../data/images/photo2-1_1.jpg\n",
      "Kyz_E2PFg_g.jpg:\n",
      "../data/images/Kyz_E2PFg_g.jpg\n",
      "h5Xg1s6rMoQ.jpg:\n",
      "../data/images/h5Xg1s6rMoQ.jpg\n",
      "IMG_20220606_172837_1.jpg:\n",
      "../data/images/IMG_20220606_172837_1.jpg\n",
      "IMG_20220923_001238_1.jpg:\n",
      "../data/images/IMG_20220923_001238_1.jpg\n",
      "1.jpg:\n",
      "../data/images/test_images/paul_rudd/1.jpg\n",
      "1.jpg:\n",
      "../data/images/test_images/angelina_jolie/1.jpg\n",
      "1.jpg:\n",
      "../data/images/test_images/kate_siegel/1.jpg\n",
      "1.jpg:\n",
      "../data/images/test_images/shea_whigham/1.jpg\n",
      "1.jpg:\n",
      "../data/images/test_images/bradley_cooper/1.jpg\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for p in Path('../data/images').rglob('*.jpg'):\n",
    "    print(f\"{p.name}:\\n{p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get encoded features for all saved images\n",
    "# saved_pictures = \"../data/images\"\n",
    "all_people_faces = {}\n",
    "# for file in saved_pictures:\n",
    "for file in Path('../data/images').rglob('*.jpg'):\n",
    "    person_face, extension = file.name.split(\".\")\n",
    "    img = cv2.imread(f'{file}')\n",
    "    cropped = mtcnn(img)\n",
    "    if cropped is not None:\n",
    "        all_people_faces[person_face] = encode(cropped)[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/alexander/Documents/Programming/ObjectDetection/.venv/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "def detect(cam=0, thres=0.7):\n",
    "    vdo = cv2.VideoCapture(cam)\n",
    "    while vdo.grab():\n",
    "        _, img0 = vdo.retrieve()\n",
    "        batch_boxes, cropped_images = mtcnn.detect_box(img0)\n",
    "\n",
    "        if cropped_images is not None:\n",
    "            for box, cropped in zip(batch_boxes, cropped_images):\n",
    "                x, y, x2, y2 = [int(x) for x in box]\n",
    "                img_embedding = encode(cropped.unsqueeze(0))\n",
    "                detect_dict = {}\n",
    "                for k, v in all_people_faces.items():\n",
    "                    detect_dict[k] = (v - img_embedding).norm().item()\n",
    "                min_key = min(detect_dict, key=detect_dict.get)\n",
    "\n",
    "                if detect_dict[min_key] >= thres:\n",
    "                    min_key = 'Undetected'\n",
    "                \n",
    "                cv2.rectangle(img0, (x, y), (x2, y2), (0, 0, 255), 2)\n",
    "                cv2.putText(\n",
    "                  img0, min_key, (x + 5, y + 10), \n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255), 1)\n",
    "                \n",
    "        ### display\n",
    "        cv2.imshow(\"output\", img0)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "detect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
