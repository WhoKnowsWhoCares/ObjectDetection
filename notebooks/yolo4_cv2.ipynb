{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# import torch\n",
    "import numpy as np\n",
    "# from art import tprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "'person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa',\n",
    "'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_object_bounding_box(image_to_process, index, box):\n",
    "    \"\"\"\n",
    "    Drawing object borders with captions\n",
    "    :param image_to_process: original image\n",
    "    :param index: index of object class defined with YOLO\n",
    "    :param box: coordinates of the area around the object\n",
    "    :return: image with marked objects\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, w, h = box\n",
    "    start = (x, y)\n",
    "    end = (x + w, y + h)\n",
    "    color = (0, 255, 0)\n",
    "    width = 2\n",
    "    final_image = cv2.rectangle(image_to_process, start, end, color, width)\n",
    "\n",
    "    start = (x, y - 10)\n",
    "    font_size = 1\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    width = 2\n",
    "    text = classes[index]\n",
    "    final_image = cv2.putText(final_image, text, start, font,\n",
    "                              font_size, color, width, cv2.LINE_AA)\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_object_count(image_to_process, objects_count):\n",
    "    \"\"\"\n",
    "    Signature of the number of found objects in the image\n",
    "    :param image_to_process: original image\n",
    "    :param objects_count: the number of objects of the desired class\n",
    "    :return: image with labeled number of found objects\n",
    "    \"\"\"\n",
    "\n",
    "    start = (10, 120)\n",
    "    font_size = 1.5\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    width = 3\n",
    "    text = \"Objects found: \" + str(objects_count)\n",
    "\n",
    "    # Text output with a stroke\n",
    "    # (so that it can be seen in different lighting conditions of the picture)\n",
    "    white_color = (255, 255, 255)\n",
    "    black_outline_color = (0, 0, 0)\n",
    "    final_image = cv2.putText(image_to_process, text, start, font, font_size,\n",
    "                              black_outline_color, width * 3, cv2.LINE_AA)\n",
    "    final_image = cv2.putText(final_image, text, start, font, font_size,\n",
    "                              white_color, width, cv2.LINE_AA)\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_yolo_object_detection(model, image_to_process, show_classes=None):\n",
    "    \"\"\"\n",
    "    Recognition and determination of the coordinates of objects on the image\n",
    "    :param image_to_process: original image\n",
    "    :return: image with marked objects and captions to them\n",
    "    \"\"\"\n",
    "    layer_names = model.getLayerNames()\n",
    "    out_layers_indexes = model.getUnconnectedOutLayers()\n",
    "    out_layers = [layer_names[index - 1] for index in out_layers_indexes]\n",
    "\n",
    "    height, width, _ = image_to_process.shape\n",
    "    blob = cv2.dnn.blobFromImage(image_to_process, 1 / 255, (608, 608),\n",
    "                                 (0, 0, 0), swapRB=True, crop=False)\n",
    "    model.setInput(blob)\n",
    "    outs = model.forward(out_layers)\n",
    "    class_indexes, class_scores, boxes = ([] for i in range(3))\n",
    "    objects_count = 0\n",
    "\n",
    "    # Starting a search for objects in an image\n",
    "    for out in outs:\n",
    "        for obj in out:\n",
    "            scores = obj[5:]\n",
    "            class_index = np.argmax(scores)\n",
    "            class_score = scores[class_index]\n",
    "            if class_score > 0:\n",
    "                center_x = int(obj[0] * width)\n",
    "                center_y = int(obj[1] * height)\n",
    "                obj_width = int(obj[2] * width)\n",
    "                obj_height = int(obj[3] * height)\n",
    "                box = [center_x - obj_width // 2, center_y - obj_height // 2,\n",
    "                       obj_width, obj_height]\n",
    "                boxes.append(box)\n",
    "                class_indexes.append(class_index)\n",
    "                class_scores.append(float(class_score))\n",
    "\n",
    "    # Selection\n",
    "    chosen_boxes = cv2.dnn.NMSBoxes(boxes, class_scores, 0.0, 0.4)\n",
    "    for box_index in chosen_boxes:\n",
    "        box_index = box_index\n",
    "        box = boxes[box_index]\n",
    "        class_index = class_indexes[box_index]\n",
    "\n",
    "        # For debugging, we draw objects included in the desired classes\n",
    "        if show_classes != None and class_index in show_classes:\n",
    "            objects_count += 1\n",
    "            image_to_process = draw_object_bounding_box(image_to_process, class_index, box)\n",
    "\n",
    "    final_image = draw_object_count(image_to_process, objects_count)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test image capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet(\"../models/yolov4-tiny.cfg\",\n",
    "                                    \"../models/yolov4-tiny.weights\")\n",
    "\n",
    "image = cv2.imread('../data/images/0je5b4V4MQ0_1.jpg')\n",
    "result = apply_yolo_object_detection(net, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 636, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_video_object_detection(model, video: str, show_classes=None):\n",
    "    \"\"\"\n",
    "    Real-time video capture and analysis\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Capturing a picture from a video\n",
    "            video_camera_capture = cv2.VideoCapture(video)\n",
    "            \n",
    "            while video_camera_capture.isOpened():\n",
    "                ret, frame = video_camera_capture.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Application of object recognition methods on a video frame from YOLO\n",
    "                frame = apply_yolo_object_detection(model, frame, show_classes=None)\n",
    "                \n",
    "                # Displaying the processed image on the screen with a reduced window size\n",
    "                frame = cv2.resize(frame, (1920 // 2, 1080 // 2))\n",
    "                cv2.imshow(\"Video Capture\", frame)\n",
    "                cv2.waitKey(1)\n",
    "            \n",
    "            video_camera_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "        except KeyboardInterrupt:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = input(\"Path to video (or URL): \")\n",
    "# look_for = input(\"What we are looking for: \").split(',')\n",
    "\n",
    "# Delete spaces\n",
    "# list_look_for = []\n",
    "# for look in look_for:\n",
    "#     list_look_for.append(look.strip())\n",
    "\n",
    "# start_video_object_detection(net, video, show_classes=list_look_for)\n",
    "start_video_object_detection(net, video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
